# Parameter-Efficient-Fine-Tuning-For-ViMedMCQA

# ğŸ¤– MÃ´ hÃ¬nh Trá»£ lÃ½ Tráº£ lá»i CÃ¢u há»i (Fine-tune + API + Gradio UI)

Má»™t há»‡ thá»‘ng hoÃ n chá»‰nh gá»“m:
- âœ… Fine-tune mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) báº±ng ká»¹ thuáº­t LoRA vá»›i Unsloth
- âœ… Giao tiáº¿p qua API (Flask/FastAPI)
- âœ… Giao diá»‡n ngÆ°á»i dÃ¹ng vá»›i Gradio Ä‘á»ƒ gá»­i cÃ¢u há»i vÃ  nháº­n Ä‘Ã¡p Ã¡n

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
ğŸ“¦project/
 â”£ ğŸ“œfinetuning.ipynb                      # Fine-tune mÃ´ hÃ¬nh LLM vá»›i LoRA + RSLORA
 â”£ ğŸ“œevaluation_form.ipynb                 # Evaluation mÃ´ hÃ¬nh
 â”£ ğŸ“deployment/                          # ThÆ° má»¥c triá»ƒn khai API vÃ  giao diá»‡n
 â”ƒ â”£ ğŸ“œServer.ipynb                       # API backend (Flask hoáº·c FastAPI + ngrok)
 â”ƒ â”£ ğŸ“œapp.py                             # Giao diá»‡n ngÆ°á»i dÃ¹ng Gradio
 â”£ ğŸ“œrequirements.txt                     # CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
 â”£ ğŸ“œREADME.md                            # TÃ i liá»‡u hÆ°á»›ng dáº«n
```

---

## ğŸ§  Fine-Tune MÃ´ HÃ¬nh NgÃ´n Ngá»¯ (LLM)

Notebook `finetuning.ipynb` sá»­ dá»¥ng thÆ° viá»‡n **Unsloth** Ä‘á»ƒ fine-tune mÃ´ hÃ¬nh **LLaMA-3.2-1B 4bit** trÃªn dataset **MedMCQA**, vá»›i ká»¹ thuáº­t **LoRA + RSLORA** nháº±m giáº£m chi phÃ­ huáº¥n luyá»‡n nhÆ°ng váº«n giá»¯ hiá»‡u quáº£.

### âš™ï¸ Cáº¥u hÃ¬nh chÃ­nh:
- `r=16`, `lora_alpha=16`, `lora_dropout=0`
- `use_rslora=True` (á»•n Ä‘á»‹nh gradient)
- Ãp dá»¥ng vÃ o cÃ¡c lá»›p: `q_proj`, `k_proj`, `v_proj`, `o_proj`, `up_proj`, `down_proj`, `gate_proj`

> âœ… MÃ´ hÃ¬nh sau khi huáº¥n luyá»‡n Ä‘Æ°á»£c Ä‘áº©y lÃªn Hugging Face Hub hoáº·c lÆ°u local Ä‘á»ƒ sá»­ dá»¥ng inference qua API.

---

## ğŸš€ Khá»Ÿi Ä‘á»™ng Server (Backend API)

1. Má»Ÿ vÃ  cháº¡y file **`Server.ipynb`** trong Jupyter Notebook.
2. Khi cháº¡y xong, má»™t Ä‘Æ°á»ng dáº«n dáº¡ng `https://xxxxx.ngrok-free.app` sáº½ xuáº¥t hiá»‡n.
3. Sao chÃ©p Ä‘Æ°á»ng dáº«n vÃ  cáº­p nháº­t vÃ o file `app.py`:
   ```python
   API_URL = "https://xxxxx.ngrok-free.app/chat"
   ```

---

## ğŸ–¥ï¸ Giao Diá»‡n NgÆ°á»i DÃ¹ng (Client Gradio)

### 1. Táº¡o mÃ´i trÆ°á»ng áº£o
```bash
python -m venv venv
```

### 2. KÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o
```bash
# Windows
venv\Scripts\activate

# macOS / Linux
source venv/bin/activate
```

### 3. CÃ i Ä‘áº·t thÆ° viá»‡n
```bash
pip install -r requirements.txt
```

### 4. Cháº¡y á»©ng dá»¥ng Gradio
```bash
python app.py
```

- Truy cáº­p táº¡i: [http://localhost:7860](http://localhost:7860)

---

## ğŸ“š Dataset & MÃ´ HÃ¬nh

- **Dataset**: [MedMCQA](https://huggingface.co/datasets/openlifescienceai/medmcqa)
- **Base model**: [`unsloth/Llama-3.2-1B-bnb-4bit`](https://huggingface.co/unsloth/Llama-3.2-1B-bnb-4bit)
- **Fine-tuning**: PEFT with LoRA + RSLoRA

---

## ğŸ§  Inference Demo

VÃ­ dá»¥ cÃ¢u há»i:

```
Question: What is the capital of France?
Choices:
A. Berlin
B. Paris
C. Madrid
D. Rome
Answer:
```

MÃ´ hÃ¬nh sáº½ tráº£ lá»i: **B. Paris**

---

## ğŸ“ Ghi chÃº

- YÃªu cáº§u Python >= 3.8
- NÃªn cháº¡y trÃªn GPU (>= 12GB náº¿u fine-tune)
- Cáº§n Internet náº¿u sá»­ dá»¥ng ngrok cho API

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [LoRA Paper (Hu et al., 2021)](https://arxiv.org/abs/2106.09685)
- [Unsloth GitHub](https://github.com/unslothai/unsloth)
- [MedMCQA Dataset](https://huggingface.co/datasets/openlifescienceai/medmcqa)

---

ğŸ› ï¸ **TÃ¡c giáº£**: [TÃªn báº¡n á»Ÿ Ä‘Ã¢y]  
ğŸ“… **Cáº­p nháº­t láº§n cuá»‘i**: ThÃ¡ng 7/2025
